{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100, RMSE: 7.1848291183281585\n",
      "Iteration 200, RMSE: 7.106073813919705\n",
      "Iteration 300, RMSE: 7.078943216794538\n",
      "Iteration 400, RMSE: 7.077612008803284\n",
      "Iteration 500, RMSE: 7.063316694259713\n",
      "Iteration 600, RMSE: 7.028641237097448\n",
      "Iteration 700, RMSE: 7.023183553131436\n",
      "Iteration 800, RMSE: 7.014067946706754\n",
      "Iteration 900, RMSE: 6.996755496903188\n",
      "Iteration 1000, RMSE: 6.987927300791501\n",
      "Iteration 100, RMSE: 6.6938034328061855\n",
      "Iteration 200, RMSE: 6.588458966157487\n",
      "Iteration 300, RMSE: 6.478139475314307\n",
      "Iteration 400, RMSE: 6.391835488039032\n",
      "Iteration 500, RMSE: 6.353899438232068\n",
      "Iteration 600, RMSE: 6.328822181178576\n",
      "Iteration 700, RMSE: 6.287663648810917\n",
      "Iteration 800, RMSE: 6.269253826613957\n",
      "Iteration 900, RMSE: 6.255156840409776\n",
      "Iteration 1000, RMSE: 6.2341113530857415\n",
      "Iteration 100, RMSE: 8.703564259880254\n",
      "Iteration 200, RMSE: 8.601213635657343\n",
      "Iteration 300, RMSE: 8.569869397619078\n",
      "Iteration 400, RMSE: 8.55823351715245\n",
      "Iteration 500, RMSE: 8.535675589407777\n",
      "Iteration 600, RMSE: 8.531253289150316\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "# Load the data from the specified 'data/' directory\n",
    "item_categories = pd.read_csv('data/item_categories.csv')\n",
    "items = pd.read_csv('data/items.csv')\n",
    "sales_train = pd.read_csv('data/sales_train.csv')\n",
    "shops = pd.read_csv('data/shops.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "# Convert the 'date' column to datetime\n",
    "sales_train['date'] = pd.to_datetime(sales_train['date'], format='%d.%m.%Y')\n",
    "\n",
    "# Aggregate the sales data by month, shop, and item\n",
    "monthly_sales = sales_train.groupby(['date_block_num', 'shop_id', 'item_id'], as_index=False).agg({\n",
    "    'item_cnt_day': 'sum',\n",
    "    'item_price': 'mean'\n",
    "}).rename(columns={'item_cnt_day': 'item_cnt_month'})\n",
    "\n",
    "# Merging with items, shops, and item categories for feature enrichment\n",
    "monthly_sales = monthly_sales.merge(items[['item_id', 'item_category_id']], on='item_id', how='left')\n",
    "monthly_sales = monthly_sales.merge(shops[['shop_id', 'shop_name']], on='shop_id', how='left')\n",
    "monthly_sales = monthly_sales.merge(item_categories[['item_category_id', 'item_category_name']], on='item_category_id', how='left')\n",
    "\n",
    "# Creating lag features to improve predictive power\n",
    "for lag in [1, 2, 3]:\n",
    "    lag_col_name = f'item_cnt_month_lag_{lag}'\n",
    "    monthly_sales[lag_col_name] = monthly_sales.groupby(['shop_id', 'item_id'])['item_cnt_month'].shift(lag)\n",
    "\n",
    "# Fill missing lag values with 0 (no sales)\n",
    "monthly_sales.fillna(0, inplace=True)\n",
    "\n",
    "# Drop columns not needed for modeling, including 'date_block_num'\n",
    "X = monthly_sales.drop(['item_cnt_month', 'shop_name', 'item_category_name', 'date_block_num'], axis=1)\n",
    "y = monthly_sales['item_cnt_month']\n",
    "\n",
    "# Time series split for cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "# Initializing XGBoost with hyperparameters\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    max_depth=8,\n",
    "    n_estimators=1000,\n",
    "    min_child_weight=300,\n",
    "    colsample_bytree=0.8,\n",
    "    subsample=0.8,\n",
    "    eta=0.3,\n",
    "    seed=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Custom early stopping\n",
    "best_rmse = float('inf')\n",
    "n_rounds_no_improve = 0\n",
    "early_stopping_rounds = 10\n",
    "\n",
    "# Using the updated root_mean_squared_error function\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Time-based cross-validation\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    eval_set = [(X_train, y_train), (X_valid, y_valid)]\n",
    "    \n",
    "    # Train the model in steps to implement early stopping manually\n",
    "    for i in range(100, 1001, 100):\n",
    "        xgb_model.n_estimators = i\n",
    "        xgb_model.fit(X_train, y_train, eval_set=eval_set, verbose=False)\n",
    "        \n",
    "        # Predict on validation set and calculate RMSE\n",
    "        y_pred = xgb_model.predict(X_valid)\n",
    "        rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "        \n",
    "        print(f\"Iteration {i}, RMSE: {rmse}\")\n",
    "        \n",
    "        # Check for early stopping\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            n_rounds_no_improve = 0\n",
    "        else:\n",
    "            n_rounds_no_improve += 1\n",
    "        \n",
    "        if n_rounds_no_improve >= early_stopping_rounds:\n",
    "            print(f\"Early stopping at iteration {i}, best RMSE: {best_rmse}\")\n",
    "            break\n",
    "\n",
    "# Save the trained model for deployment\n",
    "joblib.dump(xgb_model, 'sales_prediction_model.joblib')\n",
    "print(\"Model saved as 'sales_prediction_model.joblib'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
