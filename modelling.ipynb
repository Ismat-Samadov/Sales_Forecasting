{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: RMSE = 0.8039139882505983, R^2 = 0.9293120576622209\n",
      "Decision Tree: RMSE = 3.2531526078706373e-14, R^2 = 1.0\n",
      "Random Forest: RMSE = 0.0032960178861133876, R^2 = 0.9999988117569347\n",
      "XGBoost: RMSE = 0.0001283576835521317, R^2 = 0.9999999981979373\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Step 1: Load the Dataset\n",
    "df = pd.read_excel('data/Coffee Shop Sales.xlsx')\n",
    "\n",
    "# Step 2: Data Preprocessing\n",
    "# Calculate Total Sales as (transaction_qty * unit_price)\n",
    "df['Total Sales'] = df['transaction_qty'] * df['unit_price']\n",
    "\n",
    "# Drop any unnecessary columns\n",
    "df = df.drop(['transaction_id', 'transaction_date', 'transaction_time', 'product_detail'], axis=1)\n",
    "\n",
    "# Convert categorical variables into dummy/indicator variables\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# Define feature set X and target y\n",
    "X = df.drop(['Total Sales'], axis=1)  # Features\n",
    "y = df['Total Sales']  # Target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Model Training and Evaluation\n",
    "\n",
    "# Dictionary to store RMSE and R-squared for each model\n",
    "model_results = {}\n",
    "\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "model_results['Linear Regression'] = {'RMSE': rmse_lr, 'R^2': r2_lr}\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeRegressor()\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "rmse_dt = np.sqrt(mean_squared_error(y_test, y_pred_dt))\n",
    "r2_dt = r2_score(y_test, y_pred_dt)\n",
    "model_results['Decision Tree'] = {'RMSE': rmse_dt, 'R^2': r2_dt}\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "model_results['Random Forest'] = {'RMSE': rmse_rf, 'R^2': r2_rf}\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = XGBRegressor()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "model_results['XGBoost'] = {'RMSE': rmse_xgb, 'R^2': r2_xgb}\n",
    "\n",
    "# Step 4: Display Model Results\n",
    "for model_name, metrics in model_results.items():\n",
    "    print(f\"{model_name}: RMSE = {metrics['RMSE']}, R^2 = {metrics['R^2']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from xgboost import XGBRegressor\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# # Step 1: Load the Dataset\n",
    "# df = pd.read_excel('data/Coffee Shop Sales.xlsx')\n",
    "# print(df['store_location'].unique())\n",
    "# print(df['product_category'].unique())\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split, cross_val_score\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from xgboost import XGBRegressor\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "# import optuna\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# # Step 1: Load the Dataset\n",
    "# df = pd.read_excel('data/Coffee Shop Sales.xlsx')\n",
    "\n",
    "# # Step 2: Data Preprocessing\n",
    "# # Calculate Total Sales as (transaction_qty * unit_price)\n",
    "# df['Total Sales'] = df['transaction_qty'] * df['unit_price']\n",
    "\n",
    "# # Drop unnecessary columns\n",
    "# df = df.drop(['transaction_id', 'transaction_date', 'transaction_time', 'product_detail'], axis=1)\n",
    "\n",
    "# # Convert categorical variables into dummy/indicator variables\n",
    "# df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# # Define feature set X and target y\n",
    "# X = df.drop(['Total Sales'], axis=1)  # Features\n",
    "# y = df['Total Sales']  # Target\n",
    "\n",
    "# # Split the dataset into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Step 3: Define the objective functions for Random Forest and XGBoost with Optuna\n",
    "\n",
    "# def rf_objective(trial):\n",
    "#     \"\"\"Objective function for Random Forest optimization with Optuna.\"\"\"\n",
    "#     # Define hyperparameter search space\n",
    "#     n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "#     max_depth = trial.suggest_int('max_depth', 5, 20)\n",
    "#     min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "#     min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 4)\n",
    "    \n",
    "#     rf = RandomForestRegressor(\n",
    "#         n_estimators=n_estimators,\n",
    "#         max_depth=max_depth,\n",
    "#         min_samples_split=min_samples_split,\n",
    "#         min_samples_leaf=min_samples_leaf,\n",
    "#         random_state=42\n",
    "#     )\n",
    "    \n",
    "#     # Cross-validation\n",
    "#     cv_scores = cross_val_score(rf, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "#     return np.mean(cv_scores)\n",
    "\n",
    "# def xgb_objective(trial):\n",
    "#     \"\"\"Objective function for XGBoost optimization with Optuna.\"\"\"\n",
    "#     # Define hyperparameter search space\n",
    "#     n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "#     max_depth = trial.suggest_int('max_depth', 3, 15)\n",
    "#     learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3)\n",
    "#     colsample_bytree = trial.suggest_float('colsample_bytree', 0.3, 1.0)\n",
    "    \n",
    "#     xgb = XGBRegressor(\n",
    "#         n_estimators=n_estimators,\n",
    "#         max_depth=max_depth,\n",
    "#         learning_rate=learning_rate,\n",
    "#         colsample_bytree=colsample_bytree,\n",
    "#         random_state=42\n",
    "#     )\n",
    "    \n",
    "#     # Cross-validation\n",
    "#     cv_scores = cross_val_score(xgb, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "#     return np.mean(cv_scores)\n",
    "\n",
    "# # Step 4: Optimize Random Forest\n",
    "# print(\"Optimizing Random Forest...\")\n",
    "# rf_study = optuna.create_study(direction='maximize')\n",
    "# rf_study.optimize(rf_objective, n_trials=50)\n",
    "\n",
    "# # Step 5: Optimize XGBoost\n",
    "# print(\"Optimizing XGBoost...\")\n",
    "# xgb_study = optuna.create_study(direction='maximize')\n",
    "# xgb_study.optimize(xgb_objective, n_trials=50)\n",
    "\n",
    "# # Step 6: Train the best models using the optimized hyperparameters\n",
    "\n",
    "# # Random Forest\n",
    "# best_rf_params = rf_study.best_params\n",
    "# print(\"Best Random Forest Params: \", best_rf_params)\n",
    "# rf_model = RandomForestRegressor(**best_rf_params, random_state=42)\n",
    "# rf_model.fit(X_train, y_train)\n",
    "# y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# # XGBoost\n",
    "# best_xgb_params = xgb_study.best_params\n",
    "# print(\"Best XGBoost Params: \", best_xgb_params)\n",
    "# xgb_model = XGBRegressor(**best_xgb_params, random_state=42)\n",
    "# xgb_model.fit(X_train, y_train)\n",
    "# y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# # Step 7: Evaluate the models with the optimized parameters\n",
    "# print(\"\\nModel Performance After Optimization:\\n\")\n",
    "\n",
    "# # Random Forest\n",
    "# rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "# r2_rf = r2_score(y_test, y_pred_rf)\n",
    "# print(f\"Random Forest - RMSE: {rmse_rf}, R²: {r2_rf}\")\n",
    "\n",
    "# # XGBoost\n",
    "# rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "# r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "# print(f\"XGBoost - RMSE: {rmse_xgb}, R²: {r2_xgb}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import joblib\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from xgboost import XGBRegressor\n",
    "\n",
    "# # Load dataset\n",
    "# df = pd.read_excel('data/Coffee Shop Sales.xlsx')\n",
    "\n",
    "# # Preprocessing\n",
    "# df['Total Sales'] = df['transaction_qty'] * df['unit_price']\n",
    "# df = df.drop(['transaction_id', 'transaction_date', 'transaction_time', 'product_detail'], axis=1)\n",
    "\n",
    "# # One-hot encode categorical variables\n",
    "# df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# # Save column structure\n",
    "# joblib.dump(df.columns, 'columns.pkl')\n",
    "\n",
    "# # Define feature set X and target y\n",
    "# X = df.drop('Total Sales', axis=1)\n",
    "# y = df['Total Sales']\n",
    "\n",
    "# # Split the dataset\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Train XGBoost model\n",
    "# model = XGBRegressor()\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Save the trained model\n",
    "# joblib.dump(model, 'xgb_coffee_sales_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost RMSE: 0.0001283576835521317\n",
      "XGBoost R^2: 0.9999999981979373\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# Step 1: Load the Dataset and Preprocess\n",
    "df = pd.read_excel('data/Coffee Shop Sales.xlsx')\n",
    "\n",
    "# Extract year and month from 'transaction_date'\n",
    "df['transaction_date'] = pd.to_datetime(df['transaction_date'])\n",
    "df['year'] = df['transaction_date'].dt.year\n",
    "df['month'] = df['transaction_date'].dt.month\n",
    "\n",
    "# Calculate total sales\n",
    "df['Total Sales'] = df['transaction_qty'] * df['unit_price']\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df = df.drop(['transaction_id', 'transaction_time', 'transaction_date', 'product_detail'], axis=1)\n",
    "\n",
    "# One-Hot Encode categorical variables\n",
    "df = pd.get_dummies(df, columns=['store_location', 'product_category', 'product_type'], drop_first=True)\n",
    "\n",
    "# Save the feature columns for later use\n",
    "joblib.dump(df.columns, 'columns.pkl')\n",
    "\n",
    "# Define feature set X and target y\n",
    "X = df.drop(['Total Sales'], axis=1)\n",
    "y = df['Total Sales']\n",
    "\n",
    "# Step 2: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Train the Model\n",
    "xgb_model = XGBRegressor()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(xgb_model, 'xgb_coffee_sales_model.joblib')\n",
    "\n",
    "# Step 4: Evaluate the Model\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "rmse_xgb = mean_squared_error(y_test, y_pred_xgb, squared=False)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(f\"XGBoost RMSE: {rmse_xgb}\")\n",
    "print(f\"XGBoost R^2: {r2_xgb}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
