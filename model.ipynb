{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Load the dataset\n",
    "# df = pd.read_excel('data/Adidas US Sales Datasets.xlsx')\n",
    "\n",
    "# # Display basic information about the dataset\n",
    "# print(df.info())\n",
    "\n",
    "# # Display the first few rows to understand the data\n",
    "# print(df.head())\n",
    "\n",
    "# file_path = 'data/Adidas US Sales Datasets.xlsx'\n",
    "\n",
    "# # Load the Excel file and check the sheet names\n",
    "# xls = pd.ExcelFile(file_path)\n",
    "# xls.sheet_names\n",
    "\n",
    "# # Clean the dataset by skipping the initial empty rows and using the correct headers\n",
    "# df = pd.read_excel(file_path, sheet_name='Data Sales Adidas', skiprows=4)\n",
    "\n",
    "# # Display the cleaned data to confirm the structure\n",
    "# df.head()\n",
    "\n",
    "# df=df.drop(columns=['Unnamed: 0','Retailer ID'])\n",
    "\n",
    "# # Save the cleaned dataset to a CSV file\n",
    "# output_csv_path = 'data/Adidas_US_Sales_Cleaned.csv'\n",
    "# df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# output_csv_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(1253241097.91393),\n",
       " array([991.90177354, 221.33278234,   1.62362108]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "\n",
    "# Load the user's uploaded CSV file\n",
    "file_path = 'data/Adidas_US_Sales_Cleaned.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "\n",
    "# Selecting relevant features for the model (dropping non-numeric and categorical data)\n",
    "# We'll predict 'Total Sales' based on 'Price per Unit', 'Units Sold', and 'Operating Profit'\n",
    "X = data[['Price per Unit', 'Units Sold', 'Operating Profit']]\n",
    "y = data['Total Sales']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating and training the Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Save the trained model to a file using joblib\n",
    "model_file_path = 'data/linear_regression_model.pkl'\n",
    "joblib.dump(model, model_file_path)\n",
    "\n",
    "# Calculating the model's performance using Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Coefficients of the model\n",
    "coefficients = model.coef_\n",
    "\n",
    "# Displaying the results\n",
    "mse, coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-09 14:58:52,812] A new study created in memory with name: no-name-5efd9fc2-e98f-42ba-8148-ec9ac39b65d3\n",
      "[I 2024-10-09 14:58:52,829] Trial 0 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:52,844] Trial 1 finished with value: 264.41248400238936 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:52,860] Trial 2 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:52,875] Trial 3 finished with value: 264.41248400238936 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:52,889] Trial 4 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:52,903] Trial 5 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:52,918] Trial 6 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:52,932] Trial 7 finished with value: 264.41248400238936 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:52,945] Trial 8 finished with value: 264.41248400238936 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:52,960] Trial 9 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:52,974] Trial 10 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:52,988] Trial 11 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,001] Trial 12 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,015] Trial 13 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,030] Trial 14 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,044] Trial 15 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,059] Trial 16 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,075] Trial 17 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,093] Trial 18 finished with value: 264.41248400238936 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,107] Trial 19 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,121] Trial 20 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,135] Trial 21 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,150] Trial 22 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,165] Trial 23 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,181] Trial 24 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,196] Trial 25 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,211] Trial 26 finished with value: 264.41248400238936 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,227] Trial 27 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,242] Trial 28 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,256] Trial 29 finished with value: 264.41248400238936 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,271] Trial 30 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,286] Trial 31 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,300] Trial 32 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,316] Trial 33 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,331] Trial 34 finished with value: 264.41248400238936 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,346] Trial 35 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,362] Trial 36 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,377] Trial 37 finished with value: 264.41248400238936 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,392] Trial 38 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,407] Trial 39 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,421] Trial 40 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,436] Trial 41 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,450] Trial 42 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,465] Trial 43 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,480] Trial 44 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,493] Trial 45 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,507] Trial 46 finished with value: 264.41248400238936 and parameters: {'fit_intercept': False}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,521] Trial 47 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,536] Trial 48 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n",
      "[I 2024-10-09 14:58:53,549] Trial 49 finished with value: 59.3676250059195 and parameters: {'fit_intercept': True}. Best is trial 0 with value: 59.3676250059195.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'fit_intercept': True}\n",
      "      Actual Sales  Predicted Sales\n",
      "468            200       181.970437\n",
      "469            375       383.317586\n",
      "470            525       554.792205\n",
      "471            300       302.362774\n",
      "472            225       223.974202\n",
      "...            ...              ...\n",
      "9634           128       125.722401\n",
      "9635           128       114.972401\n",
      "9636           116        84.722401\n",
      "9637           123        76.222401\n",
      "9638           144        99.972401\n",
      "\n",
      "[667 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import optuna\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Step 1: Load the dataset\n",
    "data = pd.read_csv('data/Adidas_US_Sales_Cleaned.csv')\n",
    "\n",
    "# Step 2: Convert 'Invoice Date' to datetime and extract year and month\n",
    "data['Invoice Date'] = pd.to_datetime(data['Invoice Date'])\n",
    "data['year'] = data['Invoice Date'].dt.year\n",
    "data['month'] = data['Invoice Date'].dt.month\n",
    "\n",
    "# Step 3: Drop unnecessary columns\n",
    "data = data.drop(['Invoice Date', 'Operating Profit', 'Operating Margin'], axis=1)\n",
    "\n",
    "# Step 4: One-hot encoding for categorical variables\n",
    "data = pd.get_dummies(data, columns=['Retailer', 'Region', 'State', 'City', 'Product', 'Sales Method'], drop_first=True)\n",
    "\n",
    "# Step 5: Define the features and target\n",
    "X = data.drop(['Units Sold'], axis=1)  # Features\n",
    "y = data['Units Sold']  # Target variable\n",
    "\n",
    "# Step 6: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 7: Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Save the scaler and columns\n",
    "joblib.dump(scaler, 'scaler.joblib')\n",
    "joblib.dump(X.columns, 'columns.pkl')\n",
    "\n",
    "# Step 8: Optimize with Optuna\n",
    "# Objective function for Optuna optimization\n",
    "def objective(trial):\n",
    "    # Define hyperparameters to tune\n",
    "    fit_intercept = trial.suggest_categorical('fit_intercept', [True, False])\n",
    "\n",
    "    # Train the model with the selected hyperparameters\n",
    "    model = LinearRegression(fit_intercept=fit_intercept)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "\n",
    "# Train the final model using the best hyperparameters\n",
    "lr_model = LinearRegression(**best_params)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 9: Save the trained model\n",
    "joblib.dump(lr_model, 'linear_regression_sales_model_optuna.joblib')\n",
    "\n",
    "# Step 10: Predict for maximum date and compare actual vs predicted\n",
    "\n",
    "# Load the trained model, scaler, and columns\n",
    "lr_model = joblib.load('linear_regression_sales_model_optuna.joblib')\n",
    "scaler = joblib.load('scaler.joblib')\n",
    "original_columns = joblib.load('columns.pkl')\n",
    "\n",
    "# Find the max date in the dataset\n",
    "max_date = data['year'].max(), data['month'].max()\n",
    "\n",
    "# Extract features for the max date\n",
    "test_data = data[(data['year'] == max_date[0]) & (data['month'] == max_date[1])].drop('Units Sold', axis=1)\n",
    "\n",
    "# Scale the input data\n",
    "input_scaled = scaler.transform(test_data)\n",
    "\n",
    "# Predict sales\n",
    "predicted_qty = lr_model.predict(input_scaled)\n",
    "\n",
    "# Compare actual and predicted values\n",
    "actual_qty = y[(data['year'] == max_date[0]) & (data['month'] == max_date[1])]\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual Sales': actual_qty,\n",
    "    'Predicted Sales': predicted_qty\n",
    "})\n",
    "\n",
    "print(comparison_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presentation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Importing necessary libraries\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import optuna\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "data = pd.read_csv('data/Adidas_US_Sales_Cleaned.csv')\n",
    "\n",
    "# Step 2: Convert 'Invoice Date' to datetime and extract year and month\n",
    "data['Invoice Date'] = pd.to_datetime(data['Invoice Date'])\n",
    "data['year'] = data['Invoice Date'].dt.year\n",
    "data['month'] = data['Invoice Date'].dt.month\n",
    "\n",
    "# Step 3: Drop unnecessary columns\n",
    "data = data.drop(['Invoice Date', 'Operating Profit', 'Operating Margin'], axis=1)\n",
    "\n",
    "# Step 4: One-hot encoding for categorical variables\n",
    "data = pd.get_dummies(data, columns=['Retailer', 'Region', 'State', 'City', 'Product', 'Sales Method'], drop_first=True)\n",
    "\n",
    "# Step 5: Define the features and target\n",
    "X = data.drop(['Units Sold'], axis=1)  # Features\n",
    "y = data['Units Sold']  # Target variable\n",
    "\n",
    "# Step 6: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 7: Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Save the scaler and columns\n",
    "joblib.dump(scaler, 'scaler.joblib')\n",
    "joblib.dump(X.columns, 'columns.pkl')\n",
    "\n",
    "# Step 8: Optimize with Optuna\n",
    "# Objective function for Optuna optimization\n",
    "def objective(trial):\n",
    "    # Define hyperparameters to tune\n",
    "    fit_intercept = trial.suggest_categorical('fit_intercept', [True, False])\n",
    "\n",
    "    # Train the model with the selected hyperparameters\n",
    "    model = LinearRegression(fit_intercept=fit_intercept)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "\n",
    "# Train the final model using the best hyperparameters\n",
    "lr_model = LinearRegression(**best_params)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 9: Save the trained model\n",
    "joblib.dump(lr_model, 'linear_regression_sales_model_optuna.joblib')\n",
    "\n",
    "# Step 10: Predict for maximum date and compare actual vs predicted\n",
    "\n",
    "# Load the trained model, scaler, and columns\n",
    "lr_model = joblib.load('linear_regression_sales_model_optuna.joblib')\n",
    "scaler = joblib.load('scaler.joblib')\n",
    "original_columns = joblib.load('columns.pkl')\n",
    "\n",
    "# Find the max date in the dataset\n",
    "max_date = data['year'].max(), data['month'].max()\n",
    "\n",
    "# Extract features for the max date\n",
    "test_data = data[(data['year'] == max_date[0]) & (data['month'] == max_date[1])].drop('Units Sold', axis=1)\n",
    "\n",
    "# Scale the input data\n",
    "input_scaled = scaler.transform(test_data)\n",
    "\n",
    "# Predict sales\n",
    "predicted_qty = lr_model.predict(input_scaled)\n",
    "\n",
    "# Compare actual and predicted values\n",
    "actual_qty = y[(data['year'] == max_date[0]) & (data['month'] == max_date[1])]\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual Sales': actual_qty.values,  # Ensure alignment of values\n",
    "    'Predicted Sales': predicted_qty\n",
    "})\n",
    "\n",
    "# Display the comparison dataframe\n",
    "print(comparison_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
